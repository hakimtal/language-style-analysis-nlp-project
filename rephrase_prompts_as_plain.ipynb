{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5_OqChGKkymE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Set up your Gemini API key here\n",
        "api_key = \"\"\n",
        "\n",
        "\n",
        "\n",
        "# Define your prompt formats\n",
        "prompts = {\n",
        "    'plain': 'Rewrite the following prompt using plain language, without changing its original meaning and structure. Only answer with the rephrased prompt.'\n",
        "}\n",
        "\n",
        "rephrased_questions = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a1ff9188"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Initialize the Generative Model\n",
        "model = genai.GenerativeModel('gemini-1.5-flash-latest') # Replace with your desired model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OQyrQEZm9Q_h"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_option(text: str, option_number: int = 1) -> str:\n",
        "    # Regex to capture the block for the requested option\n",
        "    pattern = rf\"\\*\\*Option {option_number}.*?(?=\\*\\*Option \\d+|\\Z)\"\n",
        "    match = re.search(pattern, text, re.S)\n",
        "    if not match:\n",
        "        return \"\"\n",
        "\n",
        "    block = match.group()\n",
        "\n",
        "    # Remove the \"**Option N ...\" header line\n",
        "    block = re.sub(r\"^\\*\\*Option.*?\\n\", \"\", block, count=1, flags=re.S)\n",
        "\n",
        "    # Remove leading \">\" characters and optional spaces from each line\n",
        "    block = re.sub(r\"^\\s*>\\s?\", \"\", block, flags=re.M)\n",
        "\n",
        "    # Remove all bold markers \"**\"\n",
        "    block = block.replace(\"**\", \"\")\n",
        "\n",
        "    return block.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "oyQwTsZIA5wl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "folder = \"results\"\n",
        "skip_prefixes = [\n",
        "]\n",
        "\n",
        "# Create output base directory if it doesn't exist\n",
        "base_output_dir = Path(\"rephrased_prompts\")\n",
        "base_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(folder):\n",
        "    if filename.endswith(\".json\") and not any(filename.startswith(p) for p in skip_prefixes):\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        prompt_data = data['all_results']\n",
        "        rephrased_questions = []\n",
        "\n",
        "        # Extract model name from filename\n",
        "        model_match = re.search(r\"task_(.*?)_(boomer|gen_z|gen_alpha|millennial|gen_x|academic|children|id)\", filename)\n",
        "        model_name = model_match.group(1) if model_match else \"unknown_model\"\n",
        "\n",
        "        # Create subdirectory for the model\n",
        "        model_output_dir = base_output_dir / model_name\n",
        "        model_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for q in tqdm(prompt_data, desc=f\"Rephrasing prompts for {filename}\"):\n",
        "            try:\n",
        "                question_entry = {}\n",
        "                for style, prompt_text in prompts.items():\n",
        "                    full_prompt = f\"{prompt_text}\\n\\nPrompt: \\\"{q['prompt_used']}\\\"\\n\\nRephrased prompt:\"\n",
        "                    response = model.generate_content([full_prompt])\n",
        "                    question_entry[style] = response.text\n",
        "                question_entry = {**question_entry, **q}\n",
        "                rephrased_questions.append(question_entry)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n{'*'*50} STOPPED {'*'*50}\")\n",
        "                partial_path = model_output_dir / f\"rephrased_plain_{filename[:-5]}.json\"\n",
        "                with open(partial_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(rephrased_questions, f, indent=4)\n",
        "                raise e\n",
        "\n",
        "        # Save full rephrased results\n",
        "        output_path = model_output_dir / f\"rephrased_plain_{filename[:-5]}.json\"\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(rephrased_questions, f, indent=4)\n",
        "        print(f\"Rephrasing complete and results saved to '{output_path}'.\")\n",
        "\n",
        "        # Post-process to remove \"**Option 1\" and clean formatting\n",
        "        no_options_qs = rephrased_questions.copy()\n",
        "        for q in no_options_qs:\n",
        "            if \"**Option 1\" in q['plain']:\n",
        "                opt1 = extract_option(q['plain'], 1)\n",
        "                if opt1:\n",
        "                    q['plain'] = opt1\n",
        "            q['plain'] = q['plain'].replace(\"**\", \"\") + \"\\nAnswer:\"\n",
        "\n",
        "        one_option_path = model_output_dir / f\"rephrased_plain_one_option_{filename[:-5]}.json\"\n",
        "        with open(one_option_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(no_options_qs, f, indent=4)\n",
        "        print(f\"Cleaned prompts saved to '{one_option_path}'.\")\n"
      ],
      "metadata": {
        "id": "mLdyepSyos0F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}